<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>FDAs</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <h1>Model Merging with Functioanl Dual Anchor</h1>
    <p class="authors">Kexuan Shi<sup>1</sup>, Yandong Wen<sup>2</sup>, Weiyang Liu<sup>1</sup></p>
    <p class="affiliations">
      <sup>1</sup>The Chinese University of Hong Kong &nbsp;&nbsp;
      <sup>2</sup>Westlake University
    </p>
    <div class="links">
      <a href="#" class="button">[Paper]</a>
      <a href="https://github.com/Sphere-AI-Lab/FDA" class="button" target="_blank">[Code]</a>
      <a href="#" class="button">[BibTeX]</a>
    </div>
  </header>

  <img src="./docs/assets/framework_trajectory.png" alt="FDA Illustration" width="90%">
  <section id="abstract" style="text-align: center;">
    <h2 style="border-bottom: none; margin-bottom: 0.5em;">
      FDA: A New Framework for Model Merging
    </h2>
    <p style="max-width: 800px; margin: 0 auto; text-align: justify;">
      Model Merging has been an intriguing post-training strategy for integrating knowledge 
      from existing checkpoints of a shared foundation model. Existing methods focus on 
      operations in the parameter space (i.e., task vectors), thereby suffering from the complexity 
      of the parameter space. To explore more knowledge utilizations, we propose 
      <b><i>Functional Dual Anchors (FDAs)</i></b>, a framework (Figure 1(a)) that instead models 
      the knowledge in the input-representation space. Specifically, FDAs are synthetic inputs 
      whose induced gradients align with task vectors, capturing task-specific functional shifts 
      relative to the pretrained model. Then, we use the FDAs to adapt the pretrained model. FDAs provide an alternative perspective on 
      model merging by extending input-space modeling to this setting and bridging joint 
      multi-task training and post-hoc merging.
    </p>
  </section>

  <section id="intuition" style="text-align: center; margin-top: 3em;">
  <h2 style="border-bottom: none; margin-bottom: 0.5em;">
    Intuitive Undertstanding and Motivation of FDA
  </h2>
  <p style="max-width: 800px; margin: 0 auto; text-align: justify;">
    To gain an intuitive understanding of FDAs, we compare their
optimization trajectories with those of task arithmetic in Fig-
ure 2. We treat the obtained FDAs as finetuning data and op-
timize the model parameters accordingly. As shown in the right figure, optimizing with FDAs moves the model closer to the local
minima of the loss landscape (computed over eight downstream
datasets). While task vectors provide useful guidance from the
pretrained model, they quickly drift away from the loss basin,
whereas FDAs consistently guide optimization toward more fa-
vorable regions. Moreover, by capturing functional shifts in the
input space, FDAs offer greater robustness for model merging.
Unlike task vectors, which are sensitive to initialization and can
drift under different starting points, FDAs exhibit robustness to
such variations, facilitating more reliable model merging.
  </p>

  <p style="max-width: 800px; margin: 1em auto 0 auto; text-align: justify;">
    Another motivation behind FDAs is that modeling the input
space is generally easier than modeling the parameter space, as the input space tends to be more
structured. The effectiveness of modeling the input space for knowledge transfer is has been exten-
sively explored and empirically validated in the context of dataset distillation (Wang et al., 2018b;
Cazenavette et al., 2022), iterative teaching (Liu et al., 2017a; Qiu et al., 2023), dataset condensa-
tion (Zhao et al., 2021; Zhao & Bilen, 2023) and continual learning (Shin et al., 2017; Yu et al.,
2023).
  </p>
</section>

  <section id="overview">
    <h2>Overview</h2>
    <p>This work introduces <b>Functional Dual Anchors (FDAs)</b>, a framework for model merging that operates in the inputâ€“representation space instead of the parameter space. FDAs align induced gradients with task vectors to achieve efficient post-training integration of multiple finetuned models.</p>
    <img src="assets/overview.png" alt="Overview figure placeholder" class="placeholder">
  </section>

  <section id="citation">
    <h2>BibTeX</h2>
    <pre>
@inproceedings{shi2026fda,
  title={MODEL MERGING WITH FUNCTIONAL DUAL ANCHORS},
  author={Shi, Kexuan and Wen, Yandong and Liu, Weiyang},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2026}
}
    </pre>
  </section>

  <footer>
    <p>This website is adapted from Nerfies, MathVista and SGP-Bench, licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</p>
  </footer>
</body>
</html>
