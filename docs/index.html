<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MODEL MERGING WITH FUNCTIONAL DUAL ANCHORS</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <h1>MODEL MERGING WITH FUNCTIONAL DUAL ANCHORS</h1>
    <p class="authors">Kexuan Shi<sup>1</sup>, Yandong Wen<sup>2</sup>, Weiyang Liu<sup>1</sup></p>
    <p class="affiliations">
      <sup>1</sup>The Chinese University of Hong Kong &nbsp;&nbsp;
      <sup>2</sup>Westlake University
    </p>
    <div class="links">
      <a href="#" class="button">[Paper]</a>
      <a href="#" class="button">[Code]</a>
      <a href="#" class="button">[BibTeX]</a>
    </div>
  </header>

  <section id="abstract">
    <h2>Abstract</h2>
    <p>\vspace{-1.5mm}
Model merging is an efficient post-training strategy for integrating knowledge from multiple finetuned checkpoints of a shared foundation model. Existing methods operate in the parameter space, combining task vectors to mitigate conflicts, but remain constrained by parameter inconsistencies. We propose Functional Dual Anchors (FDAs), a framework that instead models the input–representation space. FDAs are synthetic inputs whose induced gradients align with task vectors, capturing task-specific functional shifts relative to the pretrained model. This perspective bridges joint multi-task training and post-hoc merging, offering both robustness and flexibility. We further introduce a principled initialization scheme and show that FDAs are complementary to parameter-centric model merging. Comprehensive experiments demonstrate the effectiveness of FDAs in model merging. ...</p>
  </section>

  <section id="overview">
    <h2>Overview</h2>
    <p>This work introduces <b>Functional Dual Anchors (FDAs)</b>, a framework for model merging that operates in the input–representation space instead of the parameter space. FDAs align induced gradients with task vectors to achieve efficient post-training integration of multiple finetuned models.</p>
    <img src="assets/overview.png" alt="Overview figure placeholder" class="placeholder">
  </section>

  <section id="citation">
    <h2>BibTeX</h2>
    <pre>
@inproceedings{shi2026fda,
  title={MODEL MERGING WITH FUNCTIONAL DUAL ANCHORS},
  author={Shi, Kexuan and Wen, Yandong and Liu, Weiyang},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2026}
}
    </pre>
  </section>

  <footer>
    <p>This website is adapted from Nerfies, MathVista and SGP-Bench, licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</p>
  </footer>
</body>
</html>
