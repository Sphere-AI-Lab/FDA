<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>FDAs</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <h1>Model Merging with Functioanl Dual Anchor</h1>
    <p class="authors">Kexuan Shi<sup>1</sup>, Yandong Wen<sup>2</sup>, Weiyang Liu<sup>1</sup></p>
    <p class="affiliations">
      <sup>1</sup>The Chinese University of Hong Kong &nbsp;&nbsp;
      <sup>2</sup>Westlake University
    </p>
    <div class="links">
      <a href="#" class="button">[Paper]</a>
      <a href="https://github.com/Sphere-AI-Lab/FDA" class="button" target="_blank">[Code]</a>
      <a href="#" class="button">[BibTeX]</a>
    </div>
  </header>

  <img src="FDA/docs/assets/framework_trajectory.png" alt="FDA Illustration" width="90%">
  <section id="abstract" style="text-align: center;">
    <h2 style="border-bottom: none; margin-bottom: 0.5em;">
      FDA: A New Framework for Model Merging
    </h2>
    <p style="max-width: 800px; margin: 0 auto; text-align: justify;">
      Model Merging has been an intriguing post-training strategy for integrating knowledge 
      from existing checkpoints of a shared foundation model. Existing methods focus on 
      operations in the parameter space (i.e., task vectors), thereby suffering from the complexity 
      of the parameter space. To explore more knowledge utilizations, we propose 
      <b><i>Functional Dual Anchors (FDAs)</i></b>, a framework (Figure 1(a)) that instead models 
      the knowledge in the input-representation space. Specifically, FDAs are synthetic inputs 
      whose induced gradients align with task vectors, capturing task-specific functional shifts 
      relative to the pretrained model. Then, we use the FDAs to adapt the pretrained model. FDAs provide an alternative perspective on 
      model merging by extending input-space modeling to this setting and bridging joint 
      multi-task training and post-hoc merging.
    </p>
  </section>

  <section id="intuition" style="text-align: center; margin-top: 3em;">
  <h2 style="border-bottom: none; margin-bottom: 0.5em;">
    Intuitive Undertstanding and Motivation of FDA
  </h2>
  <p style="max-width: 800px; margin: 0 auto; text-align: justify;">
    To gain an intuitive understanding of FDAs, we compare their
optimization trajectories with those of task arithmetic in Fig-
ure 2. We treat the obtained FDAs as finetuning data and op-
timize the model parameters accordingly. As shown in the right figure, optimizing with FDAs moves the model closer to the local
minima of the loss landscape (computed over eight downstream
datasets). While task vectors provide useful guidance from the
pretrained model, they quickly drift away from the loss basin,
whereas FDAs consistently guide optimization toward more fa-
vorable regions. Moreover, by capturing functional shifts in the
input space, FDAs offer greater robustness for model merging.
Unlike task vectors, which are sensitive to initialization and can
drift under different starting points, FDAs exhibit robustness to
such variations, facilitating more reliable model merging.
  </p>

  <p style="max-width: 800px; margin: 1em auto 0 auto; text-align: justify;">
    Another motivation behind FDAs is that modeling the input
space is generally easier than modeling the parameter space, as the input space tends to be more
structured. The effectiveness of modeling the input space for knowledge transfer is has been exten-
sively explored and empirically validated in the context of dataset distillation (Wang et al., 2018b;
Cazenavette et al., 2022), iterative teaching (Liu et al., 2017a; Qiu et al., 2023), dataset condensa-
tion (Zhao et al., 2021; Zhao & Bilen, 2023) and continual learning (Shin et al., 2017; Yu et al.,
2023).
  </p>
</section>

  <section id="performance" style="text-align: center; margin-top: 3em;">
  <h2 style="border-bottom: none; margin-bottom: 0.5em;">
      Performance of FDAs
  </h2>

  <!-- 图片展示区（可换成你的性能图表） -->
  <div style="text-align: center; margin-bottom: 1em;">
    <img src="./docs/assets/fda_performance.png" alt="FDA Performance" width="80%">
    <p style="font-size: small; color: gray;">Figure 2: Performance comparison of FDAs with other model merging methods.</p>
  </div>

  <!-- 正文 -->
  <p style="max-width: 800px; margin: 0 auto; text-align: justify;">
    To evaluate the effectiveness of <b><i>Functional Dual Anchors (FDAs)</i></b>, we conduct extensive experiments across
    multiple modalities, including vision, natural language understanding (NLP), and natural language generation (NLG).
    FDAs consistently outperform traditional parameter-space merging methods such as Task Arithmetic, DARE, and WUDI
    across a wide range of datasets and architectures.
  </p>

  <p style="max-width: 800px; margin: 1em auto 0 auto; text-align: justify;">
    In vision tasks, FDAs achieve comparable or superior accuracy to joint multi-task training while maintaining
    full modularity and no access to original data. For NLP tasks on the GLUE benchmark, FDAs demonstrate smoother
    merging trajectories and less performance degradation under conflicting task updates. For large-scale language
    models, FDAs enable effective functional adaptation between experts in domains such as mathematics and code.
    These results highlight the robustness and generality of FDAs as a unifying framework for functional model merging.
  </p>
</section>

  <section id="performance" style="text-align: center; margin-top: 3em;">
  <h2 style="border-bottom: none; margin-bottom: 0.5em;">
    The practical Aligorithms for FDAs
  </h2>

  <!-- 图片展示区（可换成你的性能图表） -->
  <div style="text-align: center; margin-bottom: 1em;">
    <img src="./docs/assets/fda_performance.png" alt="FDA Performance" width="80%">
    <p style="font-size: small; color: gray;">Figure 2: Performance comparison of FDAs with other model merging methods.</p>
  </div>

  <!-- 正文 -->
  <p style="max-width: 800px; margin: 0 auto; text-align: justify;">
    To evaluate the effectiveness of <b><i>Functional Dual Anchors (FDAs)</i></b>, we conduct extensive experiments across
    multiple modalities, including vision, natural language understanding (NLP), and natural language generation (NLG).
    FDAs consistently outperform traditional parameter-space merging methods such as Task Arithmetic, DARE, and WUDI
    across a wide range of datasets and architectures.
  </p>

  <p style="max-width: 800px; margin: 1em auto 0 auto; text-align: justify;">
    In vision tasks, FDAs achieve comparable or superior accuracy to joint multi-task training while maintaining
    full modularity and no access to original data. For NLP tasks on the GLUE benchmark, FDAs demonstrate smoother
    merging trajectories and less performance degradation under conflicting task updates. For large-scale language
    models, FDAs enable effective functional adaptation between experts in domains such as mathematics and code.
    These results highlight the robustness and generality of FDAs as a unifying framework for functional model merging.
  </p>
</section>


    <section id="performance" style="text-align: center; margin-top: 3em;">
  <h2 style="border-bottom: none; margin-bottom: 0.5em;">
    Knowledge encoded in the FDAs
  </h2>

  <!-- 图片展示区（可换成你的性能图表） -->
  <div style="text-align: center; margin-bottom: 1em;">
    <img src="./docs/assets/fda_performance.png" alt="FDA Performance" width="80%">
    <p style="font-size: small; color: gray;">Figure 2: Performance comparison of FDAs with other model merging methods.</p>
  </div>

  <!-- 正文 -->
  <p style="max-width: 800px; margin: 0 auto; text-align: justify;">
    To evaluate the effectiveness of <b><i>Functional Dual Anchors (FDAs)</i></b>, we conduct extensive experiments across
    multiple modalities, including vision, natural language understanding (NLP), and natural language generation (NLG).
    FDAs consistently outperform traditional parameter-space merging methods such as Task Arithmetic, DARE, and WUDI
    across a wide range of datasets and architectures.
  </p>

  <p style="max-width: 800px; margin: 1em auto 0 auto; text-align: justify;">
    In vision tasks, FDAs achieve comparable or superior accuracy to joint multi-task training while maintaining
    full modularity and no access to original data. For NLP tasks on the GLUE benchmark, FDAs demonstrate smoother
    merging trajectories and less performance degradation under conflicting task updates. For large-scale language
    models, FDAs enable effective functional adaptation between experts in domains such as mathematics and code.
    These results highlight the robustness and generality of FDAs as a unifying framework for functional model merging.
  </p>
</section>

  <section id="citation">
    <h2>BibTeX</h2>
    <pre>
@inproceedings{shi2026fda,
  title={MODEL MERGING WITH FUNCTIONAL DUAL ANCHORS},
  author={Shi, Kexuan and Wen, Yandong and Liu, Weiyang},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2026}
}
    </pre>
  </section>

  <footer>
    <p>This website is adapted from Nerfies, MathVista and SGP-Bench, licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</p>
  </footer>
</body>
</html>
